{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The cell below is for you to keep track of the libraries used and install those libraries quickly\n",
    "##### Ensure that the proper library names are used and the syntax of `%pip install PACKAGE_NAME` is followed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pandas \n",
    "#%pip install matplotlib\n",
    "# add commented pip installation lines for packages used as shown above for ease of testing\n",
    "# the line should be of the format %pip install PACKAGE_NAME "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DO NOT CHANGE** the filepath variable\n",
    "##### Instead, create a folder named 'data' in your current working directory and \n",
    "##### have the .parquet file inside that. A relative path *must* be used when loading data into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can have as many cells as you want for code\n",
    "import pandas as pd\n",
    "filepath = \"./data/catB_train.parquet\" \n",
    "# the initialised filepath MUST be a relative path to a folder named data that contains the parquet file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ALL** Code for machine learning and dataset analysis should be entered below. \n",
    "##### Ensure that your code is clear and readable.\n",
    "##### Comments and Markdown notes are advised to direct attention to pieces of code you deem useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = pq.read_table(filepath)\n",
    "df = tb.to_pandas()\n",
    "df.head()\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clntnum                               object\n",
       "race_desc                             object\n",
       "ctrycode_desc                         object\n",
       "clttype                               object\n",
       "stat_flag                             object\n",
       "min_occ_date                          object\n",
       "cltdob_fix                            object\n",
       "cltsex_fix                            object\n",
       "flg_substandard                      float64\n",
       "flg_is_borderline_standard           float64\n",
       "flg_is_revised_term                  float64\n",
       "flg_is_rental_flat                   float64\n",
       "flg_has_health_claim                 float64\n",
       "flg_has_life_claim                   float64\n",
       "flg_gi_claim                         float64\n",
       "flg_is_proposal                      float64\n",
       "flg_with_preauthorisation            float64\n",
       "flg_is_returned_mail                 float64\n",
       "is_consent_to_mail                   float64\n",
       "is_consent_to_email                  float64\n",
       "is_consent_to_call                   float64\n",
       "is_consent_to_sms                    float64\n",
       "is_valid_dm                          float64\n",
       "is_valid_email                       float64\n",
       "is_housewife_retiree                 float64\n",
       "is_sg_pr                             float64\n",
       "is_class_1_2                         float64\n",
       "is_dependent_in_at_least_1_policy    float64\n",
       "f_ever_declined_la                   float64\n",
       "hh_20                                 object\n",
       "pop_20                                object\n",
       "hh_size                              float64\n",
       "hh_size_est                           object\n",
       "annual_income_est                     object\n",
       "n_months_last_bought_products          int64\n",
       "flg_latest_being_lapse                 int64\n",
       "flg_latest_being_cancel                int64\n",
       "recency_lapse                        float64\n",
       "recency_cancel                       float64\n",
       "tot_inforce_pols                       int64\n",
       "tot_cancel_pols                      float64\n",
       "ape_gi_42e115                         object\n",
       "ape_ltc_1280bf                        object\n",
       "ape_grp_6fc3e6                        object\n",
       "ape_grp_de05ae                        object\n",
       "ape_inv_dcd836                        object\n",
       "ape_grp_945b5a                        object\n",
       "ape_grp_6a5788                        object\n",
       "ape_ltc_43b9d5                        object\n",
       "ape_grp_9cdedf                        object\n",
       "ape_lh_d0adeb                         object\n",
       "ape_grp_1581d7                        object\n",
       "ape_grp_22decf                        object\n",
       "ape_lh_507c37                         object\n",
       "ape_lh_839f8a                         object\n",
       "ape_inv_e9f316                        object\n",
       "ape_gi_a10d1b                         object\n",
       "ape_gi_29d435                         object\n",
       "ape_grp_caa6ff                        object\n",
       "ape_grp_fd3bfb                        object\n",
       "ape_lh_e22a6a                         object\n",
       "ape_grp_70e1dd                        object\n",
       "ape_grp_e04c3a                        object\n",
       "ape_grp_fe5fb8                        object\n",
       "ape_gi_856320                         object\n",
       "ape_grp_94baec                        object\n",
       "ape_gi_058815                         object\n",
       "ape_grp_e91421                        object\n",
       "ape_lh_f852af                         object\n",
       "ape_lh_947b15                         object\n",
       "ape_32c74c                            object\n",
       "sumins_gi_42e115                      object\n",
       "sumins_ltc_1280bf                     object\n",
       "sumins_grp_6fc3e6                     object\n",
       "sumins_grp_de05ae                     object\n",
       "sumins_inv_dcd836                     object\n",
       "sumins_grp_945b5a                     object\n",
       "sumins_grp_6a5788                     object\n",
       "sumins_ltc_43b9d5                     object\n",
       "sumins_grp_9cdedf                     object\n",
       "sumins_lh_d0adeb                      object\n",
       "sumins_grp_1581d7                     object\n",
       "sumins_grp_22decf                     object\n",
       "sumins_lh_507c37                      object\n",
       "sumins_inv_e9f316                     object\n",
       "sumins_gi_a10d1b                      object\n",
       "sumins_gi_29d435                      object\n",
       "sumins_grp_caa6ff                     object\n",
       "sumins_grp_fd3bfb                     object\n",
       "sumins_lh_e22a6a                      object\n",
       "sumins_grp_70e1dd                     object\n",
       "sumins_grp_e04c3a                     object\n",
       "sumins_grp_fe5fb8                     object\n",
       "sumins_gi_856320                      object\n",
       "sumins_grp_94baec                     object\n",
       "sumins_gi_058815                      object\n",
       "sumins_grp_e91421                     object\n",
       "sumins_lh_f852af                      object\n",
       "sumins_lh_947b15                      object\n",
       "sumins_32c74c                         object\n",
       "prempaid_gi_42e115                    object\n",
       "prempaid_ltc_1280bf                   object\n",
       "prempaid_grp_6fc3e6                   object\n",
       "prempaid_grp_de05ae                   object\n",
       "prempaid_inv_dcd836                   object\n",
       "prempaid_grp_945b5a                   object\n",
       "prempaid_grp_6a5788                   object\n",
       "prempaid_ltc_43b9d5                   object\n",
       "prempaid_grp_9cdedf                   object\n",
       "prempaid_lh_d0adeb                    object\n",
       "prempaid_grp_1581d7                   object\n",
       "prempaid_grp_22decf                   object\n",
       "prempaid_lh_507c37                    object\n",
       "prempaid_lh_839f8a                    object\n",
       "prempaid_inv_e9f316                   object\n",
       "prempaid_gi_a10d1b                    object\n",
       "prempaid_gi_29d435                    object\n",
       "prempaid_grp_caa6ff                   object\n",
       "prempaid_grp_fd3bfb                   object\n",
       "prempaid_lh_e22a6a                    object\n",
       "prempaid_grp_70e1dd                   object\n",
       "prempaid_grp_e04c3a                   object\n",
       "prempaid_grp_fe5fb8                   object\n",
       "prempaid_gi_856320                    object\n",
       "prempaid_grp_94baec                   object\n",
       "prempaid_gi_058815                    object\n",
       "prempaid_grp_e91421                   object\n",
       "prempaid_lh_f852af                    object\n",
       "prempaid_lh_947b15                    object\n",
       "prempaid_32c74c                       object\n",
       "ape_839f8a                            object\n",
       "ape_e22a6a                            object\n",
       "ape_d0adeb                            object\n",
       "ape_c4bda5                            object\n",
       "ape_ltc                               object\n",
       "ape_507c37                            object\n",
       "ape_gi                                object\n",
       "f_hold_839f8a                          int64\n",
       "f_hold_e22a6a                          int64\n",
       "f_hold_d0adeb                          int64\n",
       "f_hold_c4bda5                          int64\n",
       "f_hold_ltc                             int64\n",
       "f_hold_507c37                          int64\n",
       "f_hold_gi                              int64\n",
       "sumins_839f8a                         object\n",
       "sumins_e22a6a                         object\n",
       "sumins_d0adeb                         object\n",
       "sumins_c4bda5                         object\n",
       "sumins_ltc                            object\n",
       "sumins_507c37                         object\n",
       "sumins_gi                             object\n",
       "prempaid_839f8a                       object\n",
       "prempaid_e22a6a                       object\n",
       "prempaid_d0adeb                       object\n",
       "prempaid_c4bda5                       object\n",
       "prempaid_ltc                          object\n",
       "prempaid_507c37                       object\n",
       "prempaid_gi                           object\n",
       "lapse_ape_ltc_1280bf                  object\n",
       "lapse_ape_grp_6fc3e6                  object\n",
       "lapse_ape_grp_de05ae                  object\n",
       "lapse_ape_inv_dcd836                  object\n",
       "lapse_ape_grp_945b5a                  object\n",
       "lapse_ape_grp_6a5788                  object\n",
       "lapse_ape_ltc_43b9d5                  object\n",
       "lapse_ape_grp_9cdedf                  object\n",
       "lapse_ape_lh_d0adeb                   object\n",
       "lapse_ape_grp_1581d7                  object\n",
       "lapse_ape_grp_22decf                  object\n",
       "lapse_ape_lh_507c37                   object\n",
       "lapse_ape_lh_839f8a                   object\n",
       "lapse_ape_inv_e9f316                  object\n",
       "lapse_ape_grp_caa6ff                  object\n",
       "lapse_ape_grp_fd3bfb                  object\n",
       "lapse_ape_lh_e22a6a                   object\n",
       "lapse_ape_grp_70e1dd                  object\n",
       "lapse_ape_grp_e04c3a                  object\n",
       "lapse_ape_grp_fe5fb8                  object\n",
       "lapse_ape_grp_94baec                  object\n",
       "lapse_ape_grp_e91421                  object\n",
       "lapse_ape_lh_f852af                   object\n",
       "lapse_ape_lh_947b15                   object\n",
       "lapse_ape_32c74c                      object\n",
       "n_months_since_lapse_ltc_1280bf       object\n",
       "n_months_since_lapse_grp_6fc3e6       object\n",
       "n_months_since_lapse_grp_de05ae       object\n",
       "n_months_since_lapse_inv_dcd836       object\n",
       "n_months_since_lapse_grp_945b5a       object\n",
       "n_months_since_lapse_grp_6a5788       object\n",
       "n_months_since_lapse_ltc_43b9d5       object\n",
       "n_months_since_lapse_grp_9cdedf       object\n",
       "n_months_since_lapse_lh_d0adeb        object\n",
       "n_months_since_lapse_grp_1581d7       object\n",
       "n_months_since_lapse_grp_22decf       object\n",
       "n_months_since_lapse_lh_507c37        object\n",
       "n_months_since_lapse_lh_839f8a        object\n",
       "n_months_since_lapse_inv_e9f316       object\n",
       "n_months_since_lapse_grp_caa6ff       object\n",
       "n_months_since_lapse_grp_fd3bfb       object\n",
       "n_months_since_lapse_lh_e22a6a        object\n",
       "n_months_since_lapse_grp_70e1dd       object\n",
       "n_months_since_lapse_grp_e04c3a       object\n",
       "n_months_since_lapse_grp_fe5fb8       object\n",
       "n_months_since_lapse_grp_94baec       object\n",
       "n_months_since_lapse_grp_e91421       object\n",
       "n_months_since_lapse_lh_f852af        object\n",
       "n_months_since_lapse_lh_947b15        object\n",
       "n_months_since_lapse_32c74c           object\n",
       "f_ever_bought_839f8a                   int64\n",
       "f_ever_bought_e22a6a                   int64\n",
       "f_ever_bought_d0adeb                   int64\n",
       "f_ever_bought_c4bda5                   int64\n",
       "f_ever_bought_ltc                      int64\n",
       "f_ever_bought_507c37                   int64\n",
       "f_ever_bought_gi                       int64\n",
       "n_months_last_bought_839f8a           object\n",
       "n_months_last_bought_e22a6a           object\n",
       "n_months_last_bought_d0adeb           object\n",
       "n_months_last_bought_c4bda5           object\n",
       "n_months_last_bought_ltc              object\n",
       "n_months_last_bought_507c37           object\n",
       "n_months_last_bought_gi               object\n",
       "f_ever_bought_ltc_1280bf               int64\n",
       "f_ever_bought_grp_6fc3e6               int64\n",
       "f_ever_bought_grp_de05ae               int64\n",
       "f_ever_bought_inv_dcd836               int64\n",
       "f_ever_bought_grp_945b5a               int64\n",
       "f_ever_bought_grp_6a5788               int64\n",
       "f_ever_bought_ltc_43b9d5               int64\n",
       "f_ever_bought_grp_9cdedf               int64\n",
       "f_ever_bought_lh_d0adeb                int64\n",
       "f_ever_bought_grp_1581d7               int64\n",
       "f_ever_bought_grp_22decf               int64\n",
       "f_ever_bought_lh_507c37                int64\n",
       "f_ever_bought_lh_839f8a                int64\n",
       "f_ever_bought_inv_e9f316               int64\n",
       "f_ever_bought_grp_caa6ff               int64\n",
       "f_ever_bought_grp_fd3bfb               int64\n",
       "f_ever_bought_lh_e22a6a                int64\n",
       "f_ever_bought_grp_70e1dd               int64\n",
       "f_ever_bought_grp_e04c3a               int64\n",
       "f_ever_bought_grp_fe5fb8               int64\n",
       "f_ever_bought_grp_94baec               int64\n",
       "f_ever_bought_grp_e91421               int64\n",
       "f_ever_bought_lh_f852af                int64\n",
       "f_ever_bought_lh_947b15                int64\n",
       "f_ever_bought_32c74c                   int64\n",
       "n_months_last_bought_ltc_1280bf       object\n",
       "n_months_last_bought_grp_6fc3e6       object\n",
       "n_months_last_bought_grp_de05ae       object\n",
       "n_months_last_bought_inv_dcd836       object\n",
       "n_months_last_bought_grp_945b5a       object\n",
       "n_months_last_bought_grp_6a5788       object\n",
       "n_months_last_bought_ltc_43b9d5       object\n",
       "n_months_last_bought_grp_9cdedf       object\n",
       "n_months_last_bought_lh_d0adeb        object\n",
       "n_months_last_bought_grp_1581d7       object\n",
       "n_months_last_bought_grp_22decf       object\n",
       "n_months_last_bought_lh_507c37        object\n",
       "n_months_last_bought_lh_839f8a        object\n",
       "n_months_last_bought_inv_e9f316       object\n",
       "n_months_last_bought_grp_caa6ff       object\n",
       "n_months_last_bought_grp_fd3bfb       object\n",
       "n_months_last_bought_lh_e22a6a        object\n",
       "n_months_last_bought_grp_70e1dd       object\n",
       "n_months_last_bought_grp_e04c3a       object\n",
       "n_months_last_bought_grp_fe5fb8       object\n",
       "n_months_last_bought_grp_94baec       object\n",
       "n_months_last_bought_grp_e91421       object\n",
       "n_months_last_bought_lh_f852af        object\n",
       "n_months_last_bought_lh_947b15        object\n",
       "n_months_last_bought_32c74c           object\n",
       "f_elx                                  int64\n",
       "f_mindef_mha                           int64\n",
       "f_retail                               int64\n",
       "flg_affconnect_show_interest_ever    float64\n",
       "flg_affconnect_ready_to_buy_ever     float64\n",
       "flg_affconnect_lapse_ever            float64\n",
       "affcon_visit_days                    float64\n",
       "n_months_since_visit_affcon          float64\n",
       "clmcon_visit_days                    float64\n",
       "recency_clmcon                       float64\n",
       "recency_clmcon_regis                 float64\n",
       "hlthclaim_amt                         object\n",
       "recency_hlthclaim                    float64\n",
       "hlthclaim_cnt_success                float64\n",
       "recency_hlthclaim_success            float64\n",
       "hlthclaim_cnt_unsuccess              float64\n",
       "recency_hlthclaim_unsuccess          float64\n",
       "flg_hlthclaim_839f8a_ever            float64\n",
       "recency_hlthclaim_839f8a             float64\n",
       "flg_hlthclaim_14cb37_ever            float64\n",
       "recency_hlthclaim_14cb37             float64\n",
       "giclaim_amt                           object\n",
       "recency_giclaim                      float64\n",
       "giclaim_cnt_success                   object\n",
       "recency_giclaim_success               object\n",
       "giclaim_cnt_unsuccess                 object\n",
       "recency_giclaim_unsuccess             object\n",
       "flg_gi_claim_29d435_ever              object\n",
       "flg_gi_claim_058815_ever              object\n",
       "flg_gi_claim_42e115_ever              object\n",
       "flg_gi_claim_856320_ever              object\n",
       "f_purchase_lh                        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"f_purchase_lh\"] = df[\"f_purchase_lh\"].fillna(0)\n",
    "df[\"f_purchase_lh\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"min_occ_date\"] = pd.to_datetime(df[\"min_occ_date\"], format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "df[\"cltdob_fix\"] = pd.to_datetime(df[\"cltdob_fix\"], format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "\n",
    "df[\"hh_20\"] = pd.to_numeric(df[\"hh_20\"], errors='coerce')\n",
    "df[\"hh_20\"] = df[\"hh_20\"].astype('Int64')\n",
    "\n",
    "df[\"pop_20\"] = pd.to_numeric(df[\"pop_20\"], errors='coerce')\n",
    "df[\"pop_20\"] = df[\"pop_20\"].astype('Int64')\n",
    "\n",
    "df[\"hh_size_est\"] = pd.to_numeric(df[\"hh_size_est\"], errors='coerce')\n",
    "df[\"hh_size_est\"] = df[\"hh_size_est\"].astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_cols = ['ape_gi_42e115',\n",
    " 'ape_ltc_1280bf',\n",
    " 'ape_grp_6fc3e6',\n",
    " 'ape_grp_de05ae',\n",
    " 'ape_inv_dcd836',\n",
    " 'ape_grp_945b5a',\n",
    " 'ape_grp_6a5788',\n",
    " 'ape_ltc_43b9d5',\n",
    " 'ape_grp_9cdedf',\n",
    " 'ape_lh_d0adeb',\n",
    " 'ape_grp_1581d7',\n",
    " 'ape_grp_22decf',\n",
    " 'ape_lh_507c37',\n",
    " 'ape_lh_839f8a',\n",
    " 'ape_inv_e9f316',\n",
    " 'ape_gi_a10d1b',\n",
    " 'ape_gi_29d435',\n",
    " 'ape_grp_caa6ff',\n",
    " 'ape_grp_fd3bfb',\n",
    " 'ape_lh_e22a6a',\n",
    " 'ape_grp_70e1dd',\n",
    " 'ape_grp_e04c3a',\n",
    " 'ape_grp_fe5fb8',\n",
    " 'ape_gi_856320',\n",
    " 'ape_grp_94baec',\n",
    " 'ape_gi_058815',\n",
    " 'ape_grp_e91421',\n",
    " 'ape_lh_f852af',\n",
    " 'ape_lh_947b15',\n",
    " 'ape_32c74c',\n",
    " 'sumins_gi_42e115',\n",
    " 'sumins_ltc_1280bf',\n",
    " 'sumins_grp_6fc3e6',\n",
    " 'sumins_grp_de05ae',\n",
    " 'sumins_inv_dcd836',\n",
    " 'sumins_grp_945b5a',\n",
    " 'sumins_grp_6a5788',\n",
    " 'sumins_ltc_43b9d5',\n",
    " 'sumins_grp_9cdedf',\n",
    " 'sumins_lh_d0adeb',\n",
    " 'sumins_grp_1581d7',\n",
    " 'sumins_grp_22decf',\n",
    " 'sumins_lh_507c37',\n",
    " 'sumins_inv_e9f316',\n",
    " 'sumins_gi_a10d1b',\n",
    " 'sumins_gi_29d435',\n",
    " 'sumins_grp_caa6ff',\n",
    " 'sumins_grp_fd3bfb',\n",
    " 'sumins_lh_e22a6a',\n",
    " 'sumins_grp_70e1dd',\n",
    " 'sumins_grp_e04c3a',\n",
    " 'sumins_grp_fe5fb8',\n",
    " 'sumins_gi_856320',\n",
    " 'sumins_grp_94baec',\n",
    " 'sumins_gi_058815',\n",
    " 'sumins_grp_e91421',\n",
    " 'sumins_lh_f852af',\n",
    " 'sumins_lh_947b15',\n",
    " 'sumins_32c74c',\n",
    " 'prempaid_gi_42e115',\n",
    " 'prempaid_ltc_1280bf',\n",
    " 'prempaid_grp_6fc3e6',\n",
    " 'prempaid_grp_de05ae',\n",
    " 'prempaid_inv_dcd836',\n",
    " 'prempaid_grp_945b5a',\n",
    " 'prempaid_grp_6a5788',\n",
    " 'prempaid_ltc_43b9d5',\n",
    " 'prempaid_grp_9cdedf',\n",
    " 'prempaid_lh_d0adeb',\n",
    " 'prempaid_grp_1581d7',\n",
    " 'prempaid_grp_22decf',\n",
    " 'prempaid_lh_507c37',\n",
    " 'prempaid_lh_839f8a',\n",
    " 'prempaid_inv_e9f316',\n",
    " 'prempaid_gi_a10d1b',\n",
    " 'prempaid_gi_29d435',\n",
    " 'prempaid_grp_caa6ff',\n",
    " 'prempaid_grp_fd3bfb',\n",
    " 'prempaid_lh_e22a6a',\n",
    " 'prempaid_grp_70e1dd',\n",
    " 'prempaid_grp_e04c3a',\n",
    " 'prempaid_grp_fe5fb8',\n",
    " 'prempaid_gi_856320',\n",
    " 'prempaid_grp_94baec',\n",
    " 'prempaid_gi_058815',\n",
    " 'prempaid_grp_e91421',\n",
    " 'prempaid_lh_f852af',\n",
    " 'prempaid_lh_947b15',\n",
    " 'prempaid_32c74c',\n",
    " 'ape_839f8a',\n",
    " 'ape_e22a6a',\n",
    " 'ape_d0adeb',\n",
    " 'ape_c4bda5',\n",
    " 'ape_ltc',\n",
    " 'ape_507c37',\n",
    " 'ape_gi',\n",
    " 'f_hold_839f8a',\n",
    " 'f_hold_e22a6a',\n",
    " 'f_hold_d0adeb',\n",
    " 'f_hold_c4bda5',\n",
    " 'f_hold_ltc',\n",
    " 'f_hold_507c37',\n",
    " 'f_hold_gi',\n",
    " 'sumins_839f8a',\n",
    " 'sumins_e22a6a',\n",
    " 'sumins_d0adeb',\n",
    " 'sumins_c4bda5',\n",
    " 'sumins_ltc',\n",
    " 'sumins_507c37',\n",
    " 'sumins_gi',\n",
    " 'prempaid_839f8a',\n",
    " 'prempaid_e22a6a',\n",
    " 'prempaid_d0adeb',\n",
    " 'prempaid_c4bda5',\n",
    " 'prempaid_ltc',\n",
    " 'prempaid_507c37',\n",
    " 'prempaid_gi',\n",
    " 'lapse_ape_ltc_1280bf',\n",
    " 'lapse_ape_grp_6fc3e6',\n",
    " 'lapse_ape_grp_de05ae',\n",
    " 'lapse_ape_inv_dcd836',\n",
    " 'lapse_ape_grp_945b5a',\n",
    " 'lapse_ape_grp_6a5788',\n",
    " 'lapse_ape_ltc_43b9d5',\n",
    " 'lapse_ape_grp_9cdedf',\n",
    " 'lapse_ape_lh_d0adeb',\n",
    " 'lapse_ape_grp_1581d7',\n",
    " 'lapse_ape_grp_22decf',\n",
    " 'lapse_ape_lh_507c37',\n",
    " 'lapse_ape_lh_839f8a',\n",
    " 'lapse_ape_inv_e9f316',\n",
    " 'lapse_ape_grp_caa6ff',\n",
    " 'lapse_ape_grp_fd3bfb',\n",
    " 'lapse_ape_lh_e22a6a',\n",
    " 'lapse_ape_grp_70e1dd',\n",
    " 'lapse_ape_grp_e04c3a',\n",
    " 'lapse_ape_grp_fe5fb8',\n",
    " 'lapse_ape_grp_94baec',\n",
    " 'lapse_ape_grp_e91421',\n",
    " 'lapse_ape_lh_f852af',\n",
    " 'lapse_ape_lh_947b15',\n",
    " 'lapse_ape_32c74c',\n",
    "] #change to float64\n",
    "\n",
    "df[prod_cols] = df[prod_cols].astype('float64')\n",
    "df[[\"recency_lapse\", \"recency_cancel\", \"tot_inforce_pols\"]] = df[[\"recency_lapse\", \"recency_cancel\", \"tot_inforce_pols\"]].apply(pd.to_numeric, errors='coerce')\n",
    "df[[\"recency_lapse\", \"recency_cancel\", \"tot_inforce_pols\"]] = df[[\"recency_lapse\", \"recency_cancel\", \"tot_inforce_pols\"]].astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18572\\750366996.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[column_name] = column_encoded\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18572\\750366996.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[column_name] = column_encoded\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18572\\750366996.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[column_name] = column_encoded\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18572\\750366996.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[column_name] = column_encoded\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_cols = ['annual_income_est', 'race_desc',\n",
    " 'ctrycode_desc',\n",
    " 'clttype',\n",
    " 'stat_flag', \n",
    " 'cltsex_fix']\n",
    "\n",
    "def encode_column_with_missing_values(df, column_name):\n",
    "    # Extract rows with missing values in the specified column\n",
    "    df_missing = df[df[column_name].isna()]\n",
    "\n",
    "    # Drop rows with missing values in the specified column\n",
    "    df_cleaned = df.dropna(subset=[column_name])\n",
    "\n",
    "    # Extract and encode the specified column\n",
    "    column_to_encode = df_cleaned[[column_name]]\n",
    "    oe = OrdinalEncoder()\n",
    "    column_encoded = oe.fit_transform(column_to_encode)\n",
    "    df_cleaned[column_name] = column_encoded\n",
    "\n",
    "    # Concatenate the two parts back together\n",
    "    df_result = pd.concat([df_cleaned, df_missing], ignore_index=True)\n",
    "\n",
    "    return df_result\n",
    "\n",
    "for col in ordinal_cols:\n",
    "    df = encode_column_with_missing_values(df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.infer_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#145-158 obj to float\n",
    "cols_145_to_158 = ['sumins_839f8a',\n",
    " 'sumins_e22a6a',\n",
    " 'sumins_d0adeb',\n",
    " 'sumins_c4bda5',\n",
    " 'sumins_ltc',\n",
    " 'sumins_507c37',\n",
    " 'sumins_gi',\n",
    " 'prempaid_839f8a',\n",
    " 'prempaid_e22a6a',\n",
    " 'prempaid_d0adeb',\n",
    " 'prempaid_c4bda5',\n",
    " 'prempaid_ltc',\n",
    " 'prempaid_507c37',\n",
    " 'prempaid_gi']\n",
    "\n",
    "df[cols_145_to_158] = df[cols_145_to_158].apply(pd.to_numeric, errors='coerce')\n",
    "df[cols_145_to_158] = df[cols_145_to_158].astype(float)\n",
    "\n",
    "cols_months_snce_bought = [ 'n_months_since_lapse_ltc_1280bf',\n",
    " 'n_months_since_lapse_grp_6fc3e6',\n",
    " 'n_months_since_lapse_grp_de05ae',\n",
    " 'n_months_since_lapse_inv_dcd836',\n",
    " 'n_months_since_lapse_grp_945b5a',\n",
    " 'n_months_since_lapse_grp_6a5788',\n",
    " 'n_months_since_lapse_ltc_43b9d5',\n",
    " 'n_months_since_lapse_grp_9cdedf',\n",
    " 'n_months_since_lapse_lh_d0adeb',\n",
    " 'n_months_since_lapse_grp_1581d7',\n",
    " 'n_months_since_lapse_grp_22decf',\n",
    " 'n_months_since_lapse_lh_507c37',\n",
    " 'n_months_since_lapse_lh_839f8a',\n",
    " 'n_months_since_lapse_inv_e9f316',\n",
    " 'n_months_since_lapse_grp_caa6ff',\n",
    " 'n_months_since_lapse_grp_fd3bfb',\n",
    " 'n_months_since_lapse_lh_e22a6a',\n",
    " 'n_months_since_lapse_grp_70e1dd',\n",
    " 'n_months_since_lapse_grp_e04c3a',\n",
    " 'n_months_since_lapse_grp_fe5fb8',\n",
    " 'n_months_since_lapse_grp_94baec',\n",
    " 'n_months_since_lapse_grp_e91421',\n",
    " 'n_months_since_lapse_lh_f852af',\n",
    " 'n_months_since_lapse_lh_947b15',\n",
    " 'n_months_since_lapse_32c74c', \n",
    "  'n_months_last_bought_839f8a',\n",
    " 'n_months_last_bought_e22a6a',\n",
    " 'n_months_last_bought_d0adeb',\n",
    " 'n_months_last_bought_c4bda5',\n",
    " 'n_months_last_bought_ltc',\n",
    " 'n_months_last_bought_507c37',\n",
    " 'n_months_last_bought_gi',\n",
    "  'n_months_last_bought_ltc_1280bf',\n",
    " 'n_months_last_bought_grp_6fc3e6',\n",
    " 'n_months_last_bought_grp_de05ae',\n",
    " 'n_months_last_bought_inv_dcd836',\n",
    " 'n_months_last_bought_grp_945b5a',\n",
    " 'n_months_last_bought_grp_6a5788',\n",
    " 'n_months_last_bought_ltc_43b9d5',\n",
    " 'n_months_last_bought_grp_9cdedf',\n",
    " 'n_months_last_bought_lh_d0adeb',\n",
    " 'n_months_last_bought_grp_1581d7',\n",
    " 'n_months_last_bought_grp_22decf',\n",
    " 'n_months_last_bought_lh_507c37',\n",
    " 'n_months_last_bought_lh_839f8a',\n",
    " 'n_months_last_bought_inv_e9f316',\n",
    " 'n_months_last_bought_grp_caa6ff',\n",
    " 'n_months_last_bought_grp_fd3bfb',\n",
    " 'n_months_last_bought_lh_e22a6a',\n",
    " 'n_months_last_bought_grp_70e1dd',\n",
    " 'n_months_last_bought_grp_e04c3a',\n",
    " 'n_months_last_bought_grp_fe5fb8',\n",
    " 'n_months_last_bought_grp_94baec',\n",
    " 'n_months_last_bought_grp_e91421',\n",
    " 'n_months_last_bought_lh_f852af',\n",
    " 'n_months_last_bought_lh_947b15',\n",
    " 'n_months_last_bought_32c74c']\n",
    "\n",
    "df[cols_months_snce_bought] = df[cols_months_snce_bought].apply(pd.to_numeric, errors='coerce')\n",
    "df[cols_months_snce_bought] = df[cols_months_snce_bought].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_276_283 = [\n",
    "    'flg_affconnect_show_interest_ever',\n",
    " 'flg_affconnect_ready_to_buy_ever',\n",
    " 'flg_affconnect_lapse_ever',\n",
    " 'affcon_visit_days',\n",
    " 'n_months_since_visit_affcon',\n",
    " 'clmcon_visit_days',\n",
    " 'recency_clmcon',\n",
    " 'recency_clmcon_regis', \n",
    "]\n",
    "\n",
    "df[col_276_283] = df[col_276_283].apply(pd.to_numeric, errors='coerce')\n",
    "df[col_276_283] = df[col_276_283].astype('Int64')\n",
    "\n",
    "df['hlthclaim_amt'] = df['hlthclaim_amt'].apply(pd.to_numeric, errors='coerce')\n",
    "df['hlthclaim_amt'] = df['hlthclaim_amt'].astype(float) #284\n",
    "\n",
    "df[\"giclaim_amt\"] = df[\"giclaim_amt\"].apply(pd.to_numeric, errors='coerce')\n",
    "df[\"giclaim_amt\"] = df[\"giclaim_amt\"].astype(float)\n",
    "#df[\"f_purchase_lh\"] = df[\"f_purchase_lh\"].apply') #294\n",
    "\n",
    "df['min_occ_date'] = pd.to_datetime(df['min_occ_date'])\n",
    "df[\"min_occ_date\"] = (df['min_occ_date'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
    "\n",
    "df[\"cltdob_fix\"] = pd.to_datetime(df[\"cltdob_fix\"])\n",
    "df[\"cltdob_fix\"] = (df[\"cltdob_fix\"] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into numerical and non numerical cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = df.select_dtypes(include=[np.number]).drop(\"f_purchase_lh\", axis=1)\n",
    "non_numerical_cols = df.select_dtypes(exclude=[np.number])\n",
    "non_numerical_cols[\"f_purchase_lh\"] = df[\"f_purchase_lh\"]\n",
    "len(numerical_columns.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing the variances for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "\n",
    "# Calculate the variance for each column\n",
    "variances = numerical_columns.var()\n",
    "variances_sorted = variances.sort_values(ascending=False)\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "variances_sorted.plot(kind='bar', color='skyblue')\n",
    "plt.title('Variance of Columns')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Variance')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"median var: \", variances.median())\n",
    "print(\"45 percentile var: \", variances.quantile(0.45))\n",
    "print(\"40 percentile varr: \", variances.quantile(0.40))\n",
    "print(\"35 percentile var: \", variances.quantile(0.35))\n",
    "print(\"30 percentile var: \", variances.quantile(0.3))\n",
    "print(\"lower quartile var: \", variances.quantile(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "below_threshold_count = (variances < 0.05).sum()\n",
    "\n",
    "# Calculate the percentage\n",
    "percentage_below_threshold = (below_threshold_count / len(variances)) * 100\n",
    "percentage_below_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "correlation matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr(numeric_only=True)\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Extract the correlation of each independent variable with the target variable\n",
    "correlation_with_target = correlation_matrix['f_purchase_lh'].drop('f_purchase_lh')\n",
    "\n",
    "# Display the correlation of each independent variable with the target variable\n",
    "print(\"\\nCorrelation with Target_Var:\")\n",
    "print(correlation_with_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "target_column = \"f_purchase_lh\"\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = numerical_columns\n",
    "y = df[target_column]\n",
    "\n",
    "# Identify numeric columns\n",
    "numeric_cols = X.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Subset the DataFrame to include only numeric columns\n",
    "X_numeric = X[numeric_cols]\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "\n",
    "# Initialize the VarianceThreshold with a threshold value (adjust as needed)\n",
    "variance_threshold = 0\n",
    "selector = VarianceThreshold(threshold=variance_threshold)\n",
    "\n",
    "# Fit and transform on the training set\n",
    "X_train_filtered = selector.fit_transform(X_numeric)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X_numeric.columns[selector.get_support()]\n",
    "\n",
    "# Display or use the filtered DataFrames\n",
    "print(X_train_filtered)\n",
    "print(\"Selected Features:\", selected_features)\n",
    "print(\"num of numerical cols left: \", len(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating numerical and non-numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = numerical_columns[selected_features.tolist()]\n",
    "df = pd.concat([numerical_columns, non_numerical_cols], axis=1)\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping columns that are less than 50% filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "threshold = 0.5 * len(df)  # Set the threshold to 50% of the rows\n",
    "\n",
    "# Loop through each column\n",
    "for col in df.columns.tolist():\n",
    "    # Specify the condition for a subset of rows\n",
    "    condition = (df[\"f_purchase_lh\"] == 1) & (df[col].notna())\n",
    "    \n",
    "    # Calculate the ratio of non-null values in the column for the subset of rows\n",
    "    ratio = len(df[condition]) / len(df[df[\"f_purchase_lh\"] == 1])\n",
    "    \n",
    "    # Drop the column if more than 50% of rows are empty and the ratio is less than 0.5\n",
    "    if (df[col].isna().sum() > threshold) and (ratio < 0.5):\n",
    "        df = df.drop(columns=[col])\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop client number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"clntnum\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = df.corr()\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(correlation, vmax=1, square=True, cmap=\"YlGnBu\")\n",
    "plt.title(\"correlation between features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_col = df[\"f_purchase_lh\"]\n",
    "non_tar_col = df.drop(\"f_purchase_lh\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame and threshold is your correlation threshold\n",
    "threshold = -2  # Set your desired correlation threshold here\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = non_tar_col.corr().abs()\n",
    "\n",
    "# Create a mask for upper triangle of the correlation matrix\n",
    "\n",
    "mask = ~pd.DataFrame(np.triu(np.ones(correlation_matrix.shape), k=1), columns=correlation_matrix.columns, index=correlation_matrix.index).astype(bool)\n",
    "\n",
    "# Identify pairs of highly correlated variables\n",
    "high_corr_pairs = (correlation_matrix > threshold) & mask\n",
    "\n",
    "# List of columns to drop\n",
    "columns_to_drop = set()\n",
    "\n",
    "# Iterate through each column in the DataFrame\n",
    "for column in correlation_matrix.columns:\n",
    "    # Find other columns highly correlated with the current column\n",
    "    correlated_columns = high_corr_pairs[high_corr_pairs[column]].index.tolist()\n",
    "    \n",
    "    # If there are correlated columns, drop the one with the highest variance\n",
    "    if correlated_columns:\n",
    "        variances = non_tar_col[correlated_columns].var()\n",
    "        column_to_drop = variances.idxmax()\n",
    "        columns_to_drop.add(column_to_drop)\n",
    "\n",
    "# Drop the identified columns\n",
    "filtered_df = df.drop(columns=columns_to_drop)\n",
    "filtered_df[\"f_purchase_lh\"] = tar_col\n",
    "len(filtered_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = filtered_df.select_dtypes(include=[np.number]).drop(\"f_purchase_lh\", axis=1)\n",
    "non_numerical_cols = filtered_df.select_dtypes(exclude=[np.number])\n",
    "non_numerical_cols[\"f_purchase_lh\"] = filtered_df[\"f_purchase_lh\"]\n",
    "\n",
    "len(numerical_columns.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN inputer to fill in missing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "# Replace df with your actual DataFrame name\n",
    "\n",
    "# Identify columns with missing values\n",
    "columns_with_missing_values = numerical_columns.columns[numerical_columns.isnull().any()].tolist()\n",
    "\n",
    "# Create DataFrame for imputation\n",
    "df_for_imputation = numerical_columns[columns_with_missing_values]\n",
    "\n",
    "# Initialize KNNImputer\n",
    "# imputer = KNNImputer(n_neighbors=5)  # You can adjust the number of neighbors as needed\n",
    "imputer = KNNImputer(n_neighbors=5)  # You can adjust the number of neighbors as needed\n",
    "\n",
    "\n",
    "# Fit and transform\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df_for_imputation), columns=columns_with_missing_values)\n",
    "\n",
    "# Update original DataFrame with imputed values\n",
    "numerical_columns[columns_with_missing_values] = df_imputed\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(numerical_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([numerical_columns, non_numerical_cols], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data balancing using downsampling and SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_1 = df[df[\"f_purchase_lh\"] == 1]\n",
    "df_target_0 = df[df[\"f_purchase_lh\"] == 0]\n",
    "\n",
    "df_target_0_downsample = df_target_0.sample(frac=0.1, random_state=42)\n",
    "df = pd.concat([df_target_0_downsample, df_target_1], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=\"f_purchase_lh\").astype(float)\n",
    "y = df[\"f_purchase_lh\"].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(y_train.dtype)\n",
    "\n",
    "print('Before:', Counter(y_train))\n",
    "X_train, y_train = SMOTE().fit_resample(X_train, y_train)\n",
    "print('After:', Counter(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection using RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # feature selection\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "rfe = RFECV(estimator=DecisionTreeClassifier())\n",
    "rfe.fit(X_train, y_train)\n",
    "X_train_selected = rfe.transform(X_train)\n",
    "X_val_selected = rfe.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML model (gradient boosting ) to predict values for target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "boosted_clf = GradientBoostingClassifier(n_estimators=35) # try i = 32\n",
    "boosted_clf.fit(X_train_selected, y_train)\n",
    "    # print(\"train accuracy: \", boosted_clf.score(X_train, y_train))\n",
    "    # print(\"val accuracy: \", boosted_clf.score(X_val, y_val))\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "y_val_pred = boosted_clf.predict(X_val_selected)\n",
    "\n",
    "f1_macro = metrics.f1_score(y_val, y_val_pred, average='macro')\n",
    "print(f\"F1 Macro Score: {f1_macro}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "y_pred_train = boosted_clf.predict(X_train_selected)\n",
    "y_pred_val = boosted_clf.predict(X_val_selected)\n",
    "\n",
    "\n",
    "# Assuming you have already trained the RandomForestClassifier and obtained y_pred_train and y_pred_val\n",
    "\n",
    "# Confusion matrix for training set\n",
    "conf_matrix_val = confusion_matrix(y_val, y_pred_val)\n",
    "\n",
    "# Plotting the confusion matrix using Seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix_val, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Class 0', 'Class 1'],\n",
    "            yticklabels=['Class 0', 'Class 1'])\n",
    "plt.title('Confusion Matrix - Validation Set')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cell below is **NOT** to be removed\n",
    "##### The function is to be amended so that it accepts the given input (dataframe) and returns the required output (list). \n",
    "##### It is recommended to test the function out prior to submission\n",
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "##### The hidden_data parsed into the function below will have the same layout columns wise as the dataset *SENT* to you\n",
    "##### Thus, ensure that steps taken to modify the initial dataset to fit into the model are also carried out in the function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_hidden_data(hidden_data: pd.DataFrame   ) -> list:\n",
    "    df[\"min_occ_date\"] = pd.to_datetime(df[\"min_occ_date\"], format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "    df[\"cltdob_fix\"] = pd.to_datetime(df[\"cltdob_fix\"], format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "\n",
    "    df[\"hh_20\"] = pd.to_numeric(df[\"hh_20\"], errors='coerce')\n",
    "    df[\"hh_20\"] = df[\"hh_20\"].astype('Int64')\n",
    "\n",
    "    df[\"pop_20\"] = pd.to_numeric(df[\"pop_20\"], errors='coerce')\n",
    "    df[\"pop_20\"] = df[\"pop_20\"].astype('Int64')\n",
    "\n",
    "    df[\"hh_size_est\"] = pd.to_numeric(df[\"hh_size_est\"], errors='coerce')\n",
    "    df[\"hh_size_est\"] = df[\"hh_size_est\"].astype('Int64')\n",
    "\n",
    "    prod_cols = ['ape_gi_42e115',\n",
    "    'ape_ltc_1280bf',\n",
    "    'ape_grp_6fc3e6',\n",
    "    'ape_grp_de05ae',\n",
    "    'ape_inv_dcd836',\n",
    "    'ape_grp_945b5a',\n",
    "    'ape_grp_6a5788',\n",
    "    'ape_ltc_43b9d5',\n",
    "    'ape_grp_9cdedf',\n",
    "    'ape_lh_d0adeb',\n",
    "    'ape_grp_1581d7',\n",
    "    'ape_grp_22decf',\n",
    "    'ape_lh_507c37',\n",
    "    'ape_lh_839f8a',\n",
    "    'ape_inv_e9f316',\n",
    "    'ape_gi_a10d1b',\n",
    "    'ape_gi_29d435',\n",
    "    'ape_grp_caa6ff',\n",
    "    'ape_grp_fd3bfb',\n",
    "    'ape_lh_e22a6a',\n",
    "    'ape_grp_70e1dd',\n",
    "    'ape_grp_e04c3a',\n",
    "    'ape_grp_fe5fb8',\n",
    "    'ape_gi_856320',\n",
    "    'ape_grp_94baec',\n",
    "    'ape_gi_058815',\n",
    "    'ape_grp_e91421',\n",
    "    'ape_lh_f852af',\n",
    "    'ape_lh_947b15',\n",
    "    'ape_32c74c',\n",
    "    'sumins_gi_42e115',\n",
    "    'sumins_ltc_1280bf',\n",
    "    'sumins_grp_6fc3e6',\n",
    "    'sumins_grp_de05ae',\n",
    "    'sumins_inv_dcd836',\n",
    "    'sumins_grp_945b5a',\n",
    "    'sumins_grp_6a5788',\n",
    "    'sumins_ltc_43b9d5',\n",
    "    'sumins_grp_9cdedf',\n",
    "    'sumins_lh_d0adeb',\n",
    "    'sumins_grp_1581d7',\n",
    "    'sumins_grp_22decf',\n",
    "    'sumins_lh_507c37',\n",
    "    'sumins_inv_e9f316',\n",
    "    'sumins_gi_a10d1b',\n",
    "    'sumins_gi_29d435',\n",
    "    'sumins_grp_caa6ff',\n",
    "    'sumins_grp_fd3bfb',\n",
    "    'sumins_lh_e22a6a',\n",
    "    'sumins_grp_70e1dd',\n",
    "    'sumins_grp_e04c3a',\n",
    "    'sumins_grp_fe5fb8',\n",
    "    'sumins_gi_856320',\n",
    "    'sumins_grp_94baec',\n",
    "    'sumins_gi_058815',\n",
    "    'sumins_grp_e91421',\n",
    "    'sumins_lh_f852af',\n",
    "    'sumins_lh_947b15',\n",
    "    'sumins_32c74c',\n",
    "    'prempaid_gi_42e115',\n",
    "    'prempaid_ltc_1280bf',\n",
    "    'prempaid_grp_6fc3e6',\n",
    "    'prempaid_grp_de05ae',\n",
    "    'prempaid_inv_dcd836',\n",
    "    'prempaid_grp_945b5a',\n",
    "    'prempaid_grp_6a5788',\n",
    "    'prempaid_ltc_43b9d5',\n",
    "    'prempaid_grp_9cdedf',\n",
    "    'prempaid_lh_d0adeb',\n",
    "    'prempaid_grp_1581d7',\n",
    "    'prempaid_grp_22decf',\n",
    "    'prempaid_lh_507c37',\n",
    "    'prempaid_lh_839f8a',\n",
    "    'prempaid_inv_e9f316',\n",
    "    'prempaid_gi_a10d1b',\n",
    "    'prempaid_gi_29d435',\n",
    "    'prempaid_grp_caa6ff',\n",
    "    'prempaid_grp_fd3bfb',\n",
    "    'prempaid_lh_e22a6a',\n",
    "    'prempaid_grp_70e1dd',\n",
    "    'prempaid_grp_e04c3a',\n",
    "    'prempaid_grp_fe5fb8',\n",
    "    'prempaid_gi_856320',\n",
    "    'prempaid_grp_94baec',\n",
    "    'prempaid_gi_058815',\n",
    "    'prempaid_grp_e91421',\n",
    "    'prempaid_lh_f852af',\n",
    "    'prempaid_lh_947b15',\n",
    "    'prempaid_32c74c',\n",
    "    'ape_839f8a',\n",
    "    'ape_e22a6a',\n",
    "    'ape_d0adeb',\n",
    "    'ape_c4bda5',\n",
    "    'ape_ltc',\n",
    "    'ape_507c37',\n",
    "    'ape_gi',\n",
    "    'f_hold_839f8a',\n",
    "    'f_hold_e22a6a',\n",
    "    'f_hold_d0adeb',\n",
    "    'f_hold_c4bda5',\n",
    "    'f_hold_ltc',\n",
    "    'f_hold_507c37',\n",
    "    'f_hold_gi',\n",
    "    'sumins_839f8a',\n",
    "    'sumins_e22a6a',\n",
    "    'sumins_d0adeb',\n",
    "    'sumins_c4bda5',\n",
    "    'sumins_ltc',\n",
    "    'sumins_507c37',\n",
    "    'sumins_gi',\n",
    "    'prempaid_839f8a',\n",
    "    'prempaid_e22a6a',\n",
    "    'prempaid_d0adeb',\n",
    "    'prempaid_c4bda5',\n",
    "    'prempaid_ltc',\n",
    "    'prempaid_507c37',\n",
    "    'prempaid_gi',\n",
    "    'lapse_ape_ltc_1280bf',\n",
    "    'lapse_ape_grp_6fc3e6',\n",
    "    'lapse_ape_grp_de05ae',\n",
    "    'lapse_ape_inv_dcd836',\n",
    "    'lapse_ape_grp_945b5a',\n",
    "    'lapse_ape_grp_6a5788',\n",
    "    'lapse_ape_ltc_43b9d5',\n",
    "    'lapse_ape_grp_9cdedf',\n",
    "    'lapse_ape_lh_d0adeb',\n",
    "    'lapse_ape_grp_1581d7',\n",
    "    'lapse_ape_grp_22decf',\n",
    "    'lapse_ape_lh_507c37',\n",
    "    'lapse_ape_lh_839f8a',\n",
    "    'lapse_ape_inv_e9f316',\n",
    "    'lapse_ape_grp_caa6ff',\n",
    "    'lapse_ape_grp_fd3bfb',\n",
    "    'lapse_ape_lh_e22a6a',\n",
    "    'lapse_ape_grp_70e1dd',\n",
    "    'lapse_ape_grp_e04c3a',\n",
    "    'lapse_ape_grp_fe5fb8',\n",
    "    'lapse_ape_grp_94baec',\n",
    "    'lapse_ape_grp_e91421',\n",
    "    'lapse_ape_lh_f852af',\n",
    "    'lapse_ape_lh_947b15',\n",
    "    'lapse_ape_32c74c',\n",
    "    ] \n",
    "\n",
    "    df[prod_cols] = df[prod_cols].astype('float64')\n",
    "    df[[\"recency_lapse\", \"recency_cancel\", \"tot_inforce_pols\"]] = df[[\"recency_lapse\", \"recency_cancel\", \"tot_inforce_pols\"]].apply(pd.to_numeric, errors='coerce')\n",
    "    df[[\"recency_lapse\", \"recency_cancel\", \"tot_inforce_pols\"]] = df[[\"recency_lapse\", \"recency_cancel\", \"tot_inforce_pols\"]].astype('Int64')\n",
    "\n",
    "\n",
    "\n",
    "    ordinal_cols = ['annual_income_est', 'race_desc',\n",
    "    'ctrycode_desc',\n",
    "    'clttype',\n",
    "    'stat_flag', \n",
    "    'cltsex_fix']\n",
    "\n",
    "    def encode_column_with_missing_values(df, column_name):\n",
    "        # Extract rows with missing values in the specified column\n",
    "        df_missing = df[df[column_name].isna()]\n",
    "\n",
    "        # Drop rows with missing values in the specified column\n",
    "        df_cleaned = df.dropna(subset=[column_name])\n",
    "\n",
    "        # Extract and encode the specified column\n",
    "        column_to_encode = df_cleaned[[column_name]]\n",
    "        oe = OrdinalEncoder()\n",
    "        column_encoded = oe.fit_transform(column_to_encode)\n",
    "        df_cleaned[column_name] = column_encoded\n",
    "\n",
    "        # Concatenate the two parts back together\n",
    "        df_result = pd.concat([df_cleaned, df_missing], ignore_index=True)\n",
    "\n",
    "        return df_result\n",
    "\n",
    "    for col in ordinal_cols:\n",
    "        df = encode_column_with_missing_values(df, col)\n",
    "\n",
    "\n",
    "    df = df.infer_objects()\n",
    "\n",
    "    cols_145_to_158 = ['sumins_839f8a',\n",
    "    'sumins_e22a6a',\n",
    "    'sumins_d0adeb',\n",
    "    'sumins_c4bda5',\n",
    "    'sumins_ltc',\n",
    "    'sumins_507c37',\n",
    "    'sumins_gi',\n",
    "    'prempaid_839f8a',\n",
    "    'prempaid_e22a6a',\n",
    "    'prempaid_d0adeb',\n",
    "    'prempaid_c4bda5',\n",
    "    'prempaid_ltc',\n",
    "    'prempaid_507c37',\n",
    "    'prempaid_gi']\n",
    "\n",
    "    df[cols_145_to_158] = df[cols_145_to_158].apply(pd.to_numeric, errors='coerce')\n",
    "    df[cols_145_to_158] = df[cols_145_to_158].astype(float)\n",
    "\n",
    "    cols_months_snce_bought = [ 'n_months_since_lapse_ltc_1280bf',\n",
    "    'n_months_since_lapse_grp_6fc3e6',\n",
    "    'n_months_since_lapse_grp_de05ae',\n",
    "    'n_months_since_lapse_inv_dcd836',\n",
    "    'n_months_since_lapse_grp_945b5a',\n",
    "    'n_months_since_lapse_grp_6a5788',\n",
    "    'n_months_since_lapse_ltc_43b9d5',\n",
    "    'n_months_since_lapse_grp_9cdedf',\n",
    "    'n_months_since_lapse_lh_d0adeb',\n",
    "    'n_months_since_lapse_grp_1581d7',\n",
    "    'n_months_since_lapse_grp_22decf',\n",
    "    'n_months_since_lapse_lh_507c37',\n",
    "    'n_months_since_lapse_lh_839f8a',\n",
    "    'n_months_since_lapse_inv_e9f316',\n",
    "    'n_months_since_lapse_grp_caa6ff',\n",
    "    'n_months_since_lapse_grp_fd3bfb',\n",
    "    'n_months_since_lapse_lh_e22a6a',\n",
    "    'n_months_since_lapse_grp_70e1dd',\n",
    "    'n_months_since_lapse_grp_e04c3a',\n",
    "    'n_months_since_lapse_grp_fe5fb8',\n",
    "    'n_months_since_lapse_grp_94baec',\n",
    "    'n_months_since_lapse_grp_e91421',\n",
    "    'n_months_since_lapse_lh_f852af',\n",
    "    'n_months_since_lapse_lh_947b15',\n",
    "    'n_months_since_lapse_32c74c', \n",
    "    'n_months_last_bought_839f8a',\n",
    "    'n_months_last_bought_e22a6a',\n",
    "    'n_months_last_bought_d0adeb',\n",
    "    'n_months_last_bought_c4bda5',\n",
    "    'n_months_last_bought_ltc',\n",
    "    'n_months_last_bought_507c37',\n",
    "    'n_months_last_bought_gi',\n",
    "    'n_months_last_bought_ltc_1280bf',\n",
    "    'n_months_last_bought_grp_6fc3e6',\n",
    "    'n_months_last_bought_grp_de05ae',\n",
    "    'n_months_last_bought_inv_dcd836',\n",
    "    'n_months_last_bought_grp_945b5a',\n",
    "    'n_months_last_bought_grp_6a5788',\n",
    "    'n_months_last_bought_ltc_43b9d5',\n",
    "    'n_months_last_bought_grp_9cdedf',\n",
    "    'n_months_last_bought_lh_d0adeb',\n",
    "    'n_months_last_bought_grp_1581d7',\n",
    "    'n_months_last_bought_grp_22decf',\n",
    "    'n_months_last_bought_lh_507c37',\n",
    "    'n_months_last_bought_lh_839f8a',\n",
    "    'n_months_last_bought_inv_e9f316',\n",
    "    'n_months_last_bought_grp_caa6ff',\n",
    "    'n_months_last_bought_grp_fd3bfb',\n",
    "    'n_months_last_bought_lh_e22a6a',\n",
    "    'n_months_last_bought_grp_70e1dd',\n",
    "    'n_months_last_bought_grp_e04c3a',\n",
    "    'n_months_last_bought_grp_fe5fb8',\n",
    "    'n_months_last_bought_grp_94baec',\n",
    "    'n_months_last_bought_grp_e91421',\n",
    "    'n_months_last_bought_lh_f852af',\n",
    "    'n_months_last_bought_lh_947b15',\n",
    "    'n_months_last_bought_32c74c']\n",
    "\n",
    "    df[cols_months_snce_bought] = df[cols_months_snce_bought].apply(pd.to_numeric, errors='coerce')\n",
    "    df[cols_months_snce_bought] = df[cols_months_snce_bought].astype('Int64')\n",
    "\n",
    "\n",
    "\n",
    "    col_276_283 = [\n",
    "        'flg_affconnect_show_interest_ever',\n",
    "    'flg_affconnect_ready_to_buy_ever',\n",
    "    'flg_affconnect_lapse_ever',\n",
    "    'affcon_visit_days',\n",
    "    'n_months_since_visit_affcon',\n",
    "    'clmcon_visit_days',\n",
    "    'recency_clmcon',\n",
    "    'recency_clmcon_regis', \n",
    "    ]\n",
    "\n",
    "    df[col_276_283] = df[col_276_283].apply(pd.to_numeric, errors='coerce')\n",
    "    df[col_276_283] = df[col_276_283].astype('Int64')\n",
    "\n",
    "    df['hlthclaim_amt'] = df['hlthclaim_amt'].apply(pd.to_numeric, errors='coerce')\n",
    "    df['hlthclaim_amt'] = df['hlthclaim_amt'].astype(float) #284\n",
    "\n",
    "    df[\"giclaim_amt\"] = df[\"giclaim_amt\"].apply(pd.to_numeric, errors='coerce')\n",
    "    df[\"giclaim_amt\"] = df[\"giclaim_amt\"].astype(float)\n",
    "    #df[\"f_purchase_lh\"] = df[\"f_purchase_lh\"].apply') #294\n",
    "\n",
    "    df['min_occ_date'] = pd.to_datetime(df['min_occ_date'])\n",
    "    df[\"min_occ_date\"] = (df['min_occ_date'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
    "\n",
    "    df[\"cltdob_fix\"] = pd.to_datetime(df[\"cltdob_fix\"])\n",
    "    df[\"cltdob_fix\"] = (df[\"cltdob_fix\"] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    numerical_columns = df.select_dtypes(include=[np.number])\n",
    "    non_numerical_cols = df.select_dtypes(exclude=[np.number])\n",
    "\n",
    "\n",
    "\n",
    "    variances = numerical_columns.var()\n",
    "    variances_sorted = variances.sort_values(ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "    correlation_matrix = df.corr(numeric_only=True)\n",
    "\n",
    "\n",
    "\n",
    "    # Split the data into features and target variable\n",
    "    X = numerical_columns\n",
    "\n",
    "    # Identify numeric columns\n",
    "    numeric_cols = X.select_dtypes(include=['number']).columns\n",
    "\n",
    "    # Subset the DataFrame to include only numeric columns\n",
    "    X_numeric = X[numeric_cols]\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "\n",
    "    # Initialize the VarianceThreshold with a threshold value (adjust as needed)\n",
    "    variance_threshold = 0\n",
    "    selector = VarianceThreshold(threshold=variance_threshold)\n",
    "\n",
    "    # Fit and transform on the training set\n",
    "    X_train_filtered = selector.fit_transform(X_numeric)\n",
    "\n",
    "    # Get the selected features\n",
    "    selected_features = X_numeric.columns[selector.get_support()]\n",
    "\n",
    "\n",
    "    numerical_columns = numerical_columns[selected_features.tolist()]\n",
    "    df = pd.concat([numerical_columns, non_numerical_cols], axis=1)\n",
    "\n",
    "\n",
    "    threshold = 0.5 * len(df)  # Set the threshold to 50% of the rows\n",
    "\n",
    "    # Loop through each column\n",
    "    for col in df.columns.tolist():\n",
    "        # Specify the condition for a subset of rows\n",
    "        condition = (df[\"f_purchase_lh\"] == 1) & (df[col].notna())\n",
    "        \n",
    "        # Calculate the ratio of non-null values in the column for the subset of rows\n",
    "        ratio = len(df[condition]) / len(df[df[\"f_purchase_lh\"] == 1])\n",
    "        \n",
    "        # Drop the column if more than 50% of rows are empty and the ratio is less than 0.5\n",
    "        if (df[col].isna().sum() > threshold) and (ratio < 0.5):\n",
    "            df = df.drop(columns=[col])\n",
    "\n",
    "\n",
    "    df.drop(\"clntnum\", axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    non_tar_col = df\n",
    "\n",
    "    threshold = -2  # Set your desired correlation threshold here\n",
    "\n",
    "    # Calculate the correlation matrix\n",
    "    correlation_matrix = non_tar_col.corr().abs()\n",
    "\n",
    "    # Create a mask for upper triangle of the correlation matrix\n",
    "\n",
    "    mask = ~pd.DataFrame(np.triu(np.ones(correlation_matrix.shape), k=1), columns=correlation_matrix.columns, index=correlation_matrix.index).astype(bool)\n",
    "\n",
    "    # Identify pairs of highly correlated variables\n",
    "    high_corr_pairs = (correlation_matrix > threshold) & mask\n",
    "\n",
    "    # List of columns to drop\n",
    "    columns_to_drop = set()\n",
    "\n",
    "    # Iterate through each column in the DataFrame\n",
    "    for column in correlation_matrix.columns:\n",
    "        # Find other columns highly correlated with the current column\n",
    "        correlated_columns = high_corr_pairs[high_corr_pairs[column]].index.tolist()\n",
    "        \n",
    "        # If there are correlated columns, drop the one with the highest variance\n",
    "        if correlated_columns:\n",
    "            variances = non_tar_col[correlated_columns].var()\n",
    "            column_to_drop = variances.idxmax()\n",
    "            columns_to_drop.add(column_to_drop)\n",
    "\n",
    "    # Drop the identified columns\n",
    "    filtered_df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "\n",
    "    numerical_columns = filtered_df.select_dtypes(include=[np.number])\n",
    "    non_numerical_cols = filtered_df.select_dtypes(exclude=[np.number])\n",
    "\n",
    "\n",
    "    # Assuming your DataFrame is named df\n",
    "    # Replace df with your actual DataFrame name\n",
    "\n",
    "    # Identify columns with missing values\n",
    "    columns_with_missing_values = numerical_columns.columns[numerical_columns.isnull().any()].tolist()\n",
    "\n",
    "    # Create DataFrame for imputation\n",
    "    df_for_imputation = numerical_columns[columns_with_missing_values]\n",
    "\n",
    "    # Initialize KNNImputer\n",
    "    # imputer = KNNImputer(n_neighbors=5)  # You can adjust the number of neighbors as needed\n",
    "    imputer = KNNImputer(n_neighbors=5)  # You can adjust the number of neighbors as needed\n",
    "\n",
    "\n",
    "    # Fit and transform\n",
    "    df_imputed = pd.DataFrame(imputer.fit_transform(df_for_imputation), columns=columns_with_missing_values)\n",
    "\n",
    "    # Update original DataFrame with imputed values\n",
    "    numerical_columns[columns_with_missing_values] = df_imputed\n",
    "\n",
    "\n",
    "    df = pd.concat([numerical_columns, non_numerical_cols], axis=1)\n",
    "\n",
    "\n",
    "    result = boosted_clf.predict(df)\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell to check testing_hidden_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell should output a list of predictions.\n",
    "test_df = pd.read_parquet(filepath)\n",
    "test_df = test_df.drop(columns=[\"f_purchase_lh\"])\n",
    "print(testing_hidden_data(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please have the filename renamed and ensure that it can be run with the requirements above being met. All the best!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
